# clip_guided_diffusion

This is codebase from [openai/CLIP](https://github.com/openai/CLIP). <br/> 
CLIP (Contrastive Language-Image Pre-Training) is a neural network trained on a variety of (image, text) pairs. 

![CLIP](https://github.com/Yeoneasy/clip_guided_diffusion/assets/129255517/0a8bed9a-00db-4185-b917-8c73367a5c54)

## Prerequisites

What things you need to install the software and how to install them

```
pip install -r requirements.txt
```
### Usage

1. Download zip file
2. 

### Installing

A step by step series of examples that tell you how to get a development env running

Say what the step will be

```
Give the example
```

And repeat

```
until finished
```

End with an example of getting some data out of the system or using it for a little demo

## Running the tests

Explain how to run the automated tests for this system

### Break down into end to end tests

Explain what these tests test and why

```
Give an example
```

### And coding style tests

Explain what these tests test and why

```
Give an example
```

## Deployment

Add additional notes about how to deploy this on a live system

## Acknowledgments

* Hat tip to anyone whose code was used
* Inspiration
* etc
